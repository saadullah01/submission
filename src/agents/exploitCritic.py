import re

from agentlib import AgentWithHistory, LLMFunction
from agentlib.lib.common.parsers import BaseParser
from typing import Optional

OUTPUT_DESCRIPTION = '''
After completing the analysis, you MUST output the report in the following specified format.

```
<report>
<analysis>...</analysis>
<decision>...</decision>
<possible></possible>
<feedback>...</feedback>
</report>
```

Within <analysis></analysis>, replace ... with the analysis of the exploit.
Within <decision></decision>, replace ... with the decision whether the exploit is correct or not. ONLY use "yes" (for correct exploit) or "no" (for incorrect exploit) as the decision.
Within <possible></possible>, replace ... with the decision whether it is possible to correct the exploit or not (ONLY if the exploit is incorrect). ONLY use "yes" or "no". (If the exploit is correct add "n/a" to this field).
Within <feedback></feedback>, replace ... with feedback on how to correct the exploit if it is incorrect (if the exploit is correct or it is not possible to improve the exploit, add "n/a" to this field).
'''

class MyParser(BaseParser):
    MAX_FIX_FORMAT_TRIES = 3

    def get_format_instructions(self) -> str:
        return OUTPUT_DESCRIPTION

    def invoke(self, msg, *args, **kwargs) -> dict:
        response = msg.content
        if isinstance(response, list):
            response = ' '.join(response)
        return self.parse(response)
    
    def fix_patch_format(self, text: str) -> str:
        fix_llm = LLMFunction.create(
            'Fix the format of the current report according to the format instructions.\n\n# CURRENT REPORT\n{{ info.current_report }}\n\n# OUTPUT FORMAT\n{{ info.output_format }}',
            model='gpt-4o-mini',
            temperature=0.0
        )
        fixed_text = fix_llm(
            info = dict(
                current_report = text,
                output_format = self.get_format_instructions()
            )
        )
        return fixed_text
    
    def raise_format_error(self) -> None:
        raise ValueError(f'ðŸ¤¡ Output format is not correct!!')

    def parse(self, text: str) -> dict:
        try_itr = 1
        while try_itr <= self.MAX_FIX_FORMAT_TRIES:
            try:
                m = re.search(r'<analysis>(.*?)</analysis>', text, re.DOTALL)
                analysis = m.group(1) if m else self.raise_format_error()
                m = re.search(r'<decision>(.*?)</decision>', text, re.DOTALL)
                decision = m.group(1) if m else self.raise_format_error()
                if decision not in ['yes', 'no']:
                    raise ValueError(f'ðŸ¤¡ Decision must be either "yes" or "no", got: {decision}')
                m = re.search(r'<possible>(.*?)</possible>', text, re.DOTALL)
                possible = m.group(1) if m else self.raise_format_error()
                if possible not in ['yes', 'no', 'n/a']:
                    raise ValueError(f'ðŸ¤¡ Possible must be either "yes" or "no", got: {possible}')
                m = re.search(r'<feedback>(.*?)</feedback>', text, re.DOTALL)
                feedback = m.group(1) if m else self.raise_format_error()
                print(f"ðŸª– Critic Response: '''\n{text}\n'''")
                print(f'âœ… Successfully parsed the output!')
                return dict(
                    analysis=analysis.strip(),
                    decision=decision.strip(),
                    possible=possible.strip(),
                    feedback=feedback.strip()
                )
            except Exception as e:
                print(f'ðŸ¤¡ Regex Error: {e}')
                print(f'ðŸ¤¡ Trying to fix the format ... Attempt {try_itr}!!')
                text = self.fix_patch_format(text)
                try_itr += 1

class ExploitCritic(AgentWithHistory[dict, str]):
    __LLM_MODEL__ = 'o4-mini'
    __SYSTEM_PROMPT_TEMPLATE__ = 'exploitCritic/exploitCritic.system.j2'
    __USER_PROMPT_TEMPLATE__ = 'exploitCritic/exploitCritic.user.j2'
    __OUTPUT_PARSER__ = MyParser

    EXPLOIT_LOGS: Optional[str]

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.EXPLOIT_LOGS = kwargs.get('exploit_logs')
    
    def get_input_vars(self, *args, **kwargs) -> dict:
        vars = super().get_input_vars(*args, **kwargs)
        vars.update(
            EXPLOIT_LOGS = self.EXPLOIT_LOGS
        )
        return vars
    
    def get_cost(self, *args, **kw) -> float:
        total_cost = 0
        # We have to sum up all the costs of the LLM used by the agent
        for model_name, token_usage in self.token_usage.items():
            total_cost += token_usage.get_costs(model_name)['total_cost']
        return total_cost
