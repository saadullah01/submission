import re
import os

from agentlib import AgentWithHistory, LLMFunction
from agentlib.lib.common.parsers import BaseParser
from typing import Optional
from toolbox.tools import TOOLS

OUTPUT_DESCRIPTION = '''
After completing the analysis, you MUST output the exploit in the specified format.

```
<report>
<success>...</success>
<exploit>...</exploit>
<poc>...</poc>
</report>
```

Within <success>...</success>, replace ... with the information if the exploit was successful or not, ONLY use "yes" or "no".
Within <exploit>...</exploit>, replace ... with all the details of the exploit.
Within <poc>...</poc>, replace ... with the python script of the proof-of-concept of the exploit such that it could be run in the given project environment. DO NOT ENCLOSE THE SCRIPT IN TRIPLE BACKTICKS OR TRIPLE DOUBLE QUOTES, JUST PROVIDE THE SCRIPT.
'''

class MyParser(BaseParser):
    MAX_FIX_FORMAT_TRIES = 3

    def get_format_instructions(self) -> str:
        return OUTPUT_DESCRIPTION

    def invoke(self, msg, *args, **kwargs) -> dict | str:
        response = msg['output']
        if isinstance(response, list):
            response = ' '.join(response)
        if response == 'Agent stopped due to max iterations.':
            return response
        return self.parse(response)

    def fix_patch_format(self, text: str) -> str:
        fix_llm = LLMFunction.create(
            'Fix the format of the current report according to the format instructions.\n\n# CURRENT REPORT\n{{ info.current_report }}\n\n# OUTPUT FORMAT\n{{ info.output_format }}',
            model='gpt-4o-mini',
            temperature=0.0
        )
        fixed_text = fix_llm(
            info = dict(
                current_report = text,
                output_format = self.get_format_instructions()
            )
        )
        return fixed_text
    
    def raise_format_error(self) -> None:
        raise ValueError(f'ðŸ¤¡ Output format is not correct!!')

    def parse(self, text: str) -> dict:
        try_itr = 1
        while try_itr <= self.MAX_FIX_FORMAT_TRIES:
            try:
                m = re.search(r'<success>(.*?)</success>', text, re.DOTALL)
                success = m.group(1).strip() if m else self.raise_format_error()
                m = re.search(r'<exploit>(.*?)</exploit>', text, re.DOTALL)
                exploit = m.group(1) if m else self.raise_format_error()
                m = re.search(r'<poc>(.*?)</poc>', text, re.DOTALL)
                poc = m.group(1) if m else self.raise_format_error()

                # check for ``` or ```python
                if poc.startswith('```'):
                    poc = poc.strip()
                    poc = poc[poc.index('\n')+1:]
                    poc = poc[:poc.rindex('\n')]

                print(f'âœ… Successfully parsed the output!')
                return dict(
                    success = success.strip(),
                    exploit = exploit.strip(),
                    poc = poc.strip()
                )
            except Exception as e:
                print(f'ðŸ¤¡ Regex Error: {e}')
                print(f'ðŸ¤¡ Trying to fix the format ... Attempt {try_itr}!!')
                text = self.fix_patch_format(text)
                try_itr += 1

class Exploiter(AgentWithHistory[dict, str]):
    __LLM_MODEL__ = 'o3'
    __SYSTEM_PROMPT_TEMPLATE__ = 'exploiter/exploiter.system.j2'
    __USER_PROMPT_TEMPLATE__ = 'exploiter/exploiter.user.j2'
    __OUTPUT_PARSER__ = MyParser
    __MAX_TOOL_ITERATIONS__ = 60

    # general
    PROJECT_DIR_TREE: Optional[str]

    # from knowledge builder
    CVE_KNOWLEDGE: Optional[str]

    # from pre-reqs builder
    PROJECT_OVERVIEW: Optional[str]

    # from repo builder
    PROJECT_ACCESS: Optional[str]

    # feedback
    CRITIC_FEEDBACK: Optional[str]
    FEEDBACK = Optional[str]
    ERROR = Optional[str]

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.CVE_KNOWLEDGE = kwargs.get('cve_knowledge')
        self.PROJECT_OVERVIEW = kwargs.get('project_overview')
        self.PROJECT_DIR_TREE = kwargs.get('project_dir_tree')
        self.REPO_BUILD = kwargs.get('repo_build')
        self.FEEDBACK = kwargs.get('feedback')
        self.CRITIC_FEEDBACK = kwargs.get('critic_feedback')
    
    def get_input_vars(self, *args, **kwargs) -> dict:
        vars = super().get_input_vars(*args, **kwargs)
        vars.update(
            PROJECT_DIR_TREE = self.PROJECT_DIR_TREE,
            CVE_KNOWLEDGE = self.CVE_KNOWLEDGE,
            PROJECT_OVERVIEW = self.PROJECT_OVERVIEW,
            PROJECT_ACCESS = self.REPO_BUILD['access'],
            FEEDBACK = self.FEEDBACK,
            CRITIC_FEEDBACK = self.CRITIC_FEEDBACK,
            ERROR = None
        )
        return vars

    def get_available_tools(self):
        return TOOLS.values()
    
    def get_cost(self, *args, **kw) -> float:
        total_cost = 0
        # We have to sum up all the costs of the LLM used by the agent
        for model_name, token_usage in self.token_usage.items():
            total_cost += token_usage.get_costs(model_name)['total_cost']
        return total_cost
